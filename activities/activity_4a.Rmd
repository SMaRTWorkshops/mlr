---
title: "MLR Day 4A<br/>Hands-on Activity"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE
)
```

## Setup

```{r, message=FALSE}
# Set all of this to get the EXACT SAME results on all platforms
set.seed(2025, "Mersenne-Twister", "Inversion", "Rejection")

library(tidyverse)
library(tidymodels)
library(kernlab) # install this if you don't have it
tidymodels_prefer()

water <- read_csv("https://tinyurl.com/mlr-water")
```

## Hands-on Activity

Our goal is to build a model to predict `Potability`.


<ol>
  <li>Split the data into 80% training and 20% testing, stratified by the outcome variable.</li>
  <li>Prepare a 10-fold cross-validation within the training set, similarly stratified.</li>
  <li>Create a recipe that predicts the outcome variable from all other variables.</li>
  <ul>
    <li>Add a step to drop all predictors with near-zero variance.</li>
    <li>Add a step to drop all highly correlated predictors.</li>
    <li>Add a step to drop all linear combination predictors.</li>
    <li>Add a step to transform all predictors using the Yeo-Johnson approach.</li>
  </ul>
  <li>Set up a model using `svm_linear()`</li>
  <ul>
    <li>Tune the `cost` parameter</li>
    <li>Set the mode to classification</li>
    <li>Set the engine to `"kernlab"`</li>
  </ul>
  <li>Combine the model and recipe into a workflow.</li>
  <li>Prepare the hyperparameters for tuning.</li>
  <li>Tune the hyperparameters using a grid search of size 20.</li>
  <ul>
    <li>If you are on a weak computer, maybe reduce to size 10.</li>
    <li>(For reference, my desktop finished size=20 in around 2 minutes.)</li>
  </ul>
  <li>Finalize the workflow using the parameters with the best AUC ROC.</li>
  <li>Calculate and examine the final model's testing set metrics. Did it do okay?</li>
  <li>Repeat this process but change the model to `svm_rbf()`. Was this better?</li>
  <ul>
    <li>You may want to give these new objects new names (to avoid overwriting the older ones).</li>
  </ul>
</ol>

---

## Answer key

<p><details><summary>Click here to view the answer key</summary><blockquote>
#### Part 1

```{r}
pot_split <- initial_split(water, prop = 0.8, strata = Potability)
pot_train <- training(pot_split)
pot_test <- testing(pot_split)
```

#### Part 2

```{r}
pot_folds <- vfold_cv(pot_train, v = 10, strata = Potability)
```

#### Part 3
```{r}
pot_recipe <-
  recipe(pot_train, formula = Potability ~ .) %>%
  step_mutate(Potability = factor(Potability, levels = c("unsafe", "safe"))) %>%
  step_nzv(all_predictors()) %>%
  step_corr(all_predictors()) %>%
  step_lincomb(all_predictors()) %>%
  step_YeoJohnson(all_predictors())
```

#### Part 4
```{r}
svm_model <-
  svm_linear(cost = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab")
```

#### Part 5
```{r}
pot_wflow <-
  workflow() %>%
  add_recipe(pot_recipe) %>%
  add_model(svm_model)
```

#### Part 6
```{r}
pot_param <-
  svm_model %>%
  extract_parameter_set_dials() %>%
  finalize(pot_folds)
```

#### Part 7
```{r pot, cache=TRUE}
pot_tune <-
  pot_wflow %>%
  tune_grid(
    resamples = pot_folds,
    grid = 20,
    param_info = pot_param
  )

autoplot(pot_tune)
```

#### Part 8
```{r}
pot_param_final <- select_best(pot_tune, metric = "roc_auc")

pot_wflow_final <- finalize_workflow(pot_wflow, pot_param_final)
```

#### Part 9
```{r}
pot_final <- last_fit(pot_wflow_final, pot_split)

collect_metrics(pot_final)
```
An ROC AUC of 0.54 is not very good at all! The accuracy is nearly 60% but then again, around 60% of the water sources were unsafe (so if you just guessed that they were all unsafe, your accuracy would be 60%).

### Part 10
```{r rbf, cache=TRUE}
rbf_model <-
  svm_rbf(cost = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab")

rbf_wflow <-
  workflow() %>%
  add_recipe(pot_recipe) %>%
  add_model(rbf_model)

rbf_param <-
  rbf_model %>%
  extract_parameter_set_dials() %>%
  finalize(pot_folds)

rbf_tune <-
  rbf_wflow %>%
  tune_grid(
    resamples = pot_folds,
    grid = 20,
    param_info = rbf_param
  )

rbf_param_final <- select_best(rbf_tune, metric = "roc_auc")

rbf_wflow_final <- finalize_workflow(rbf_wflow, rbf_param_final)

rbf_final <- last_fit(rbf_wflow_final, pot_split)

collect_metrics(rbf_final)
```

An ROC AUC of 0.74 looks better. The RBF kernel seemed to help a lot.

</blockquote></details></p>
